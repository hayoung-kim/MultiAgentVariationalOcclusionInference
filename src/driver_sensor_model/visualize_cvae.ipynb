{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import torch.nn as nn\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import hickle as hkl\n",
    "import pickle as pkl\n",
    "import pdb\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "import io\n",
    "import PIL.Image\n",
    "import multiprocessing as mp\n",
    "import tikzplotlib\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from src.utils.utils_model import to_var\n",
    "from src.driver_sensor_model.models_cvae import VAE\n",
    "from src.utils.data_generator import *\n",
    "from src.utils.interaction_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "nt = 10\n",
    "num_states = 7\n",
    "grid_shape = (20, 30)\n",
    "  \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "dir = '/data/INTERACTION-Dataset-DR-v1_1/Processed_data_new_goal/driver_sensor_dataset/'\n",
    "\n",
    "# Test data.\n",
    "data_file_states = os.path.join(dir, 'states_test.hkl')\n",
    "data_file_grids = os.path.join(dir, 'label_grids_test.hkl')\n",
    "data_file_sources = os.path.join(dir, 'sources_test.hkl')\n",
    "\n",
    "data_test = SequenceGenerator(data_file_state=data_file_states, data_file_grid=data_file_grids, source_file=data_file_sources, nt=nt,\n",
    "                 batch_size=None, shuffle=False, sequence_start_mode='unique', norm=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(data_test,\n",
    "        batch_size=len(data_test), shuffle=False,\n",
    "        num_workers=mp.cpu_count()-1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x_test, batch_y_test, sources_test in test_loader:\n",
    "    batch_x_test, batch_y_test_orig = batch_x_test.to(device), batch_y_test.to(device)\n",
    "    batch_y_test_orig = batch_y_test_orig.view(batch_y_test_orig.shape[0],1,20,30)\n",
    "    y_full = unnormalize(batch_x_test.cpu().data.numpy(), nt)\n",
    "    pos_x = y_full[:,:,0]\n",
    "    pos_y = y_full[:,:,1]\n",
    "    orientation = y_full[:,:,2]\n",
    "    cos_theta = np.cos(orientation)\n",
    "    sin_theta = np.sin(orientation)\n",
    "    vel_x = y_full[:,:,3]\n",
    "    vel_y = y_full[:,:,4]\n",
    "    speed = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    acc_x = y_full[:,:,5]\n",
    "    acc_y = y_full[:,:,6]\n",
    "\n",
    "    # Project the acceleration on the orientation vector to get longitudinal acceleration.\n",
    "    dot_prod = acc_x * cos_theta + acc_y * sin_theta\n",
    "    sign = np.sign(dot_prod)\n",
    "    acc_proj_x = dot_prod * cos_theta\n",
    "    acc_proj_y = dot_prod * sin_theta\n",
    "\n",
    "    acc_proj_sign = sign * np.sqrt(acc_proj_x**2 + acc_proj_y**2)\n",
    "\n",
    "    batch_size = batch_y_test_orig.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "folder_vae = '/models/cvae'\n",
    "name_vae = 'lstm_1_Adam_z_100_lr_0.001_rand_123_norm_True_kl_start_0_finish_1.0_center_10000.0_mutual_info_const_alpha_1.5_epochs_30_batch_256'\n",
    "\n",
    "vae = VAE(\n",
    "    encoder_layer_sizes_p=[7, 5],\n",
    "    n_lstms=1,\n",
    "    latent_size=100,\n",
    "    decoder_layer_sizes=[256, 600], # used to be 10\n",
    "    dim=4\n",
    "    )\n",
    "\n",
    "vae = vae.cuda()\n",
    "\n",
    "save_filename = os.path.join(folder_vae, name_vae) + 'epoch_30_vae.pt'\n",
    "\n",
    "with open(save_filename, 'rb') as f:\n",
    "    state_dict = torch.load(f)\n",
    "    vae.load_state_dict(state_dict)\n",
    "\n",
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon_y_inf_most_likely, alpha_p, alpha_p_lin, full_c, z = vae.inference(n=1, c=batch_x_test, mode='most_likely')\n",
    "    recon_x_inf, _, _, _, _ = vae.inference(n=100, c=batch_x_test, mode='all')\n",
    "print(recon_y_inf_most_likely.shape, batch_y_test_orig.shape)\n",
    "print(torch.max(recon_y_inf_most_likely), torch.min(recon_y_inf_most_likely))\n",
    "\n",
    "grid_shape = (20,30)\n",
    "recon_y_inf_np = np.reshape(recon_y_inf_most_likely.cpu().data.numpy(), (-1, grid_shape[0], grid_shape[1]))\n",
    "y_np = np.reshape(batch_y_test_orig.cpu().data.numpy(), (-1, grid_shape[0], grid_shape[1]))\n",
    "print(recon_y_inf_np.shape, y_np.shape)\n",
    "\n",
    "recon_y_inf_np_pred = (recon_y_inf_np >= 0.6).astype(float)\n",
    "recon_y_inf_np_pred[recon_y_inf_np <= 0.4] = 0.0\n",
    "recon_y_inf_np_pred[np.logical_and(recon_y_inf_np < 0.6, recon_y_inf_np > 0.4)] = 0.5\n",
    "\n",
    "acc = np.mean(recon_y_inf_np_pred == y_np)\n",
    "mse = np.mean((recon_y_inf_np - y_np)**2)\n",
    "print('Acc: ', acc, 'MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all latent classes.\n",
    "recon_y_inf_all, _, _, _, _ = vae.inference(n=1, c=batch_x_test, mode='all')\n",
    "recon_y_inf_all_np = recon_y_inf_all.cpu().data.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "grid = ImageGrid(fig, 111,\n",
    "                 nrows_ncols=(10, 10),\n",
    "                 axes_pad=0.1,\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, recon_y_inf_all_np[:,0]):\n",
    "    ax.matshow(im, cmap='gray_r', vmin=0, vmax=1)\n",
    "    ax.set_xticks([], [])\n",
    "    ax.set_yticks([], [])\n",
    "plt.savefig('all_latent_classes_vae.png')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the three most likely modes VAE: slowing down.\n",
    "sample = np.where(np.sum(acc_proj_sign < -1.5, axis=-1) > 0)[0][16]\n",
    "print('sample: ', sample)                                                      \n",
    "print('acceleration: ', acc_proj_sign[sample])\n",
    "print('speed: ', speed[sample])\n",
    "print('probabilitiies: ', torch.sort(alpha_p[sample])[0])\n",
    "\n",
    "recon_y_inf_1, _, _, _, _ = vae.inference(n=1, c=torch.unsqueeze(batch_x_test[sample], dim=0), mode='multimodal', k=1)\n",
    "recon_y_inf_np_1 = np.reshape(recon_y_inf_1.cpu().data.numpy(), (-1, grid_shape[0], grid_shape[1]))\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box') # 'datalim'\n",
    "plt.scatter(pos_x[sample], pos_y[sample])\n",
    "plt.savefig(str(sample) + '_traj_dec.png')\n",
    "tikzplotlib.save(str(sample) + '_traj_dec.tex')\n",
    "plt.figure()\n",
    "plt.matshow(recon_y_inf_np_1[0], cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('models/' + str(sample) + '_mode_1_' + str(torch.sort(alpha_p[sample])[0][-1].cpu().data.numpy()) + '_dec.png', pad_inches=0.0)\n",
    "plt.show()\n",
    "\n",
    "recon_y_inf_2, _, _, _, _ = vae.inference(n=1, c=torch.unsqueeze(batch_x_test[sample], dim=0), mode='multimodal', k=2)\n",
    "recon_y_inf_np_2 = np.reshape(recon_y_inf_2.cpu().data.numpy(), (-1, grid_shape[0], grid_shape[1]))\n",
    "\n",
    "plt.matshow(recon_y_inf_np_2[0], cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('models/' + str(sample) + '_mode_2_' + str(torch.sort(alpha_p[sample])[0][-2].cpu().data.numpy()) + '_dec.png', pad_inches=0.0)\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(batch_y_test_orig[sample,0].cpu().data.numpy(), cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('models/' + str(sample) + '_gt_dec.png', pad_inches=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the most likely modes VAE: constant speed.\n",
    "print(np.sum(np.sum(np.logical_and(np.abs(acc_proj_sign) < 10, speed > 5.0), axis=-1) > 9), speed.shape)\n",
    "sample = np.where(np.logical_and(np.sum(np.logical_and(np.abs(acc_proj_sign) < 0.25, speed > 5.0), axis=-1) > 9, alpha_p.cpu().detach().numpy()[:,27] > 0.3))[0][7]\n",
    "print('sample: ', sample)                                                      \n",
    "print('acceleration: ', acc_proj_sign[sample])\n",
    "print('speed: ', speed[sample])\n",
    "print('probabilitiies: ', torch.sort(alpha_p[sample])[0])\n",
    "\n",
    "recon_y_inf_1, _, _, _, _ = vae.inference(n=1, c=torch.unsqueeze(batch_x_test[sample], dim=0), mode='multimodal', k=1)\n",
    "recon_y_inf_np_1 = np.reshape(recon_y_inf_1.cpu().data.numpy(), (-1, grid_shape[0], grid_shape[1]))\n",
    "\n",
    "plt.gca().set_aspect('equal', adjustable='box') # 'datalim'\n",
    "plt.scatter(pos_x[sample], pos_y[sample])\n",
    "plt.savefig(str(sample) + '_traj_const.png')\n",
    "tikzplotlib.save(str(sample) + '_traj_const.tex')\n",
    "plt.figure()\n",
    "plt.matshow(recon_y_inf_np_1[0], cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('models/' + str(sample) + '_mode_1_' + str(torch.sort(alpha_p[sample])[0][-1].cpu().data.numpy()) + '_const.png', pad_inches=0.0)\n",
    "plt.show()\n",
    "\n",
    "recon_y_inf_2, _, _, _, _ = vae.inference(n=1, c=torch.unsqueeze(batch_x_test[sample], dim=0), mode='multimodal', k=2)\n",
    "recon_y_inf_np_2 = np.reshape(recon_y_inf_2.cpu().data.numpy(), (-1, grid_shape[0], grid_shape[1]))\n",
    "\n",
    "plt.matshow(recon_y_inf_np_2[0], cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('models/' + str(sample) + '_mode_2_' + str(torch.sort(alpha_p[sample])[0][-2].cpu().data.numpy()) + '_const.png', pad_inches=0.0)\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(batch_y_test_orig[sample,0].cpu().data.numpy(), cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('models/' + str(sample) + '_gt_const.png', pad_inches=0.0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
